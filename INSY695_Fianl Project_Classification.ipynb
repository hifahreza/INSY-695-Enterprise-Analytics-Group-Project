{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc848f2",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ccdaf",
   "metadata": {},
   "source": [
    "## Data Importing and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "24133b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing the dataset\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('churn.csv')\n",
    "\n",
    "##Defining features and target variaible\n",
    "#Dropping State, Churn (target variable), Total_day_charge, Total_eve_charge, Total_night_charge, and Total_intl_charge (high correlation with minutes)\n",
    "X = data.drop(columns=['Churn', 'Total_day_charge', 'Total_eve_charge', 'Total_night_charge', 'Total_intl_charge']) \n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "#Defining target variable\n",
    "y = data['Churn']\n",
    "\n",
    "##Dividing the dataset into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf076d56",
   "metadata": {},
   "source": [
    "## Data Cleaning and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f59e8482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##Filling null entries of numerical features with the median of each and Z-standardizing it\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X_train_num = X_train.select_dtypes(include=[np.number])\n",
    "X_train_cat = X_train[[\"State\", \"Area_code\", \"International_plan\", \"Voice_mail_plan\"]]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "##Transforming categorical features and combining it with the numerical features\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(X_train_num)\n",
    "cat_attribs = [\"State\", \"Area_code\", \"International_plan\", \"Voice_mail_plan\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "X_train = full_pipeline.fit_transform(X_train)\n",
    "\n",
    "#Transforming X_train format from sparse matrix to matrix\n",
    "import scipy.sparse\n",
    "X_train = X_train.todense()\n",
    "\n",
    "##PCA transformation\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "\n",
    "##Transforming test dataset using pipeline defined above and PCA\n",
    "X_test_num = X_test.select_dtypes(include=[np.number])\n",
    "X_test_cat = X_test[[\"State\", \"Area_code\", \"International_plan\", \"Voice_mail_plan\"]]\n",
    "\n",
    "X_test = full_pipeline.fit_transform(X_test)\n",
    "X_test = X_test.todense()\n",
    "\n",
    "pca.fit(X_test)\n",
    "X_test = pca.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53579f00",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3cd87be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier performance metrics:\n",
      "   Accuracy  Precision  Recall  Model Training Time\n",
      "0   0.85206        1.0     0.0              0.00136\n",
      "\n",
      "Logistic regression performance metrics:\n",
      "   Accuracy  Precision  Recall  Model Training Time\n",
      "0   0.85206        1.0     0.0             0.004906\n",
      "\n",
      "Random forest performance metrics:\n",
      "   Accuracy  Precision    Recall  Model Training Time\n",
      "0  0.801498   0.153846  0.075949             0.288834\n",
      "\n",
      "Gradient boosting performance metrics:\n",
      "   Accuracy  Precision    Recall  Model Training Time\n",
      "0  0.818352   0.178571  0.063291              0.15907\n",
      "\n",
      "LightGBM performance metrics:\n",
      "   Accuracy  Precision    Recall  Model Training Time\n",
      "0  0.808989   0.151515  0.063291             0.093911\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:08:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost performance metrics:\n",
      "   Accuracy  Precision    Recall  Model Training Time\n",
      "0  0.807116   0.147059  0.063291             0.717068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Importing performance measure metrics\n",
    "import timeit\n",
    "from sklearn import metrics\n",
    "\n",
    "##Generating basic dummy classifier model\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "start = timeit.default_timer()\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "stop = timeit.default_timer()\n",
    "dummy_time = stop-start\n",
    "\n",
    "y_test_pred = dummy_clf.predict(X_test)\n",
    "dummy_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "dummy_precision = metrics.precision_score(y_test, y_test_pred, zero_division=1)\n",
    "dummy_recall = metrics.recall_score(y_test, y_test_pred, zero_division=1)\n",
    "\n",
    "dummy_performance = [[dummy_accuracy,dummy_precision,dummy_recall,dummy_time]]\n",
    "dummy_performance = pd.DataFrame(dummy_performance, columns=['Accuracy','Precision','Recall',\n",
    "                                                             'Model Training Time'])\n",
    "print('Dummy classifier performance metrics:')\n",
    "print(dummy_performance)\n",
    "print('')\n",
    "\n",
    "##Generating basic logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "\n",
    "start = timeit.default_timer()\n",
    "log_clf.fit(X_train, y_train)\n",
    "stop = timeit.default_timer()\n",
    "log_time = stop-start\n",
    "\n",
    "y_test_pred = log_clf.predict(X_test)\n",
    "log_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "log_precision = metrics.precision_score(y_test, y_test_pred, zero_division=1)\n",
    "log_recall = metrics.recall_score(y_test, y_test_pred, zero_division=1)\n",
    "\n",
    "log_performance = [[log_accuracy,log_precision,log_recall,log_time]]\n",
    "log_performance = pd.DataFrame(log_performance, columns=['Accuracy','Precision','Recall',\n",
    "                                                         'Model Training Time'])\n",
    "print('Logistic regression performance metrics:')\n",
    "print(log_performance)\n",
    "print('')\n",
    "\n",
    "##Generating basic random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "start = timeit.default_timer()\n",
    "rf_clf.fit(X_train, y_train)\n",
    "stop = timeit.default_timer()\n",
    "rf_time = stop-start\n",
    "\n",
    "y_test_pred = rf_clf.predict(X_test)\n",
    "rf_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "rf_precision = metrics.precision_score(y_test, y_test_pred, zero_division=1)\n",
    "rf_recall = metrics.recall_score(y_test, y_test_pred, zero_division=1)\n",
    "\n",
    "rf_performance = [[rf_accuracy,rf_precision,rf_recall,rf_time]]\n",
    "rf_performance = pd.DataFrame(rf_performance, columns=['Accuracy','Precision','Recall',\n",
    "                                                       'Model Training Time'])\n",
    "print('Random forest performance metrics:')\n",
    "print(rf_performance)\n",
    "print('')\n",
    "\n",
    "##Generating basic gradient boosting model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "\n",
    "start = timeit.default_timer()\n",
    "gb_clf.fit(X_train, y_train)\n",
    "stop = timeit.default_timer()\n",
    "gb_time = stop-start\n",
    "\n",
    "y_test_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "gb_precision = metrics.precision_score(y_test, y_test_pred, zero_division=1)\n",
    "gb_recall = metrics.recall_score(y_test, y_test_pred, zero_division=1)\n",
    "\n",
    "gb_performance = [[gb_accuracy,gb_precision,gb_recall,gb_time]]\n",
    "gb_performance = pd.DataFrame(gb_performance, columns=['Accuracy','Precision','Recall',\n",
    "                                                       'Model Training Time'])\n",
    "print('Gradient boosting performance metrics:')\n",
    "print(gb_performance)\n",
    "print('')\n",
    "\n",
    "##Generating basic lightgbm model\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier()\n",
    "\n",
    "start = timeit.default_timer()\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "stop = timeit.default_timer()\n",
    "lgbm_time = stop-start\n",
    "\n",
    "y_test_pred = lgbm_clf.predict(X_test)\n",
    "lgbm_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "lgbm_precision = metrics.precision_score(y_test, y_test_pred, zero_division=1)\n",
    "lgbm_recall = metrics.recall_score(y_test, y_test_pred, zero_division=1)\n",
    "\n",
    "lgbm_performance = [[lgbm_accuracy,lgbm_precision,lgbm_recall,lgbm_time]]\n",
    "lgbm_performance = pd.DataFrame(lgbm_performance, columns=['Accuracy','Precision','Recall',\n",
    "                                                           'Model Training Time'])\n",
    "print('LightGBM performance metrics:')\n",
    "print(lgbm_performance)\n",
    "print('')\n",
    "\n",
    "##Generating basic gradient boosting model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier()\n",
    "\n",
    "start = timeit.default_timer()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "stop = timeit.default_timer()\n",
    "xgb_time = stop-start\n",
    "\n",
    "y_test_pred = xgb_clf.predict(X_test)\n",
    "xgb_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "xgb_precision = metrics.precision_score(y_test, y_test_pred, zero_division=1)\n",
    "xgb_recall = metrics.recall_score(y_test, y_test_pred, zero_division=1)\n",
    "\n",
    "xgb_performance = [[xgb_accuracy,xgb_precision,xgb_recall,xgb_time]]\n",
    "xgb_performance = pd.DataFrame(xgb_performance, columns=['Accuracy','Precision','Recall',\n",
    "                                                         'Model Training Time'])\n",
    "print('XGBoost performance metrics:')\n",
    "print(xgb_performance)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8699b662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
